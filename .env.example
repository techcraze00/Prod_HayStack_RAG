# ─────────────────────────────────────────────────────────
# RAG3 System Configuration
# Copy to .env and adjust values
# ─────────────────────────────────────────────────────────

# PostgreSQL (required)
POSTGRES_URI=postgresql://postgres:password@localhost:5432/rag_system
POSTGRES_VECTOR_TABLE=chunks
POSTGRES_SUMMARY_TABLE=universal_summaries

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_VISION_MODEL=llava
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
RERANKER_MODEL=qllama/bge-reranker-v2-m3
OLLAMA_NUM_CTX=8192

# Docling model for parsing
DOCLING_MODEL_PATH=/Users/kunal/My Works/downloaded_models/granite-docling-258M-mlx

# Groq (optional — for faster LLM inference)
GROQ_API_KEYS=[]
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_BATCH_BUFFER=1.5
GROQ_BATCH_SIZE=10
GROQ_BATCH_COOLDOWN=30.0

# Processing
CHUNK_SIZE=512
CHUNK_OVERLAP=50
SEMANTIC_THRESHOLD=0.7

# Retrieval
VECTOR_TOP_K=10
RERANK_TOP_K=5
MAX_AGENT_ITERATIONS=5

# File Paths
PARSED_DOCS_DIR=./parsed_docs

# ── Enhancement 1: Hybrid Search ──────────────────────────
HYBRID_SEARCH_ENABLED=false
HYBRID_VECTOR_WEIGHT=0.7
HYBRID_BM25_WEIGHT=0.3
HYBRID_RETRIEVAL_K=20

# ── Enhancement 2: Contextual Retrieval ───────────────────
CONTEXTUAL_RETRIEVAL_ENABLED=false
CONTEXT_BATCH_SIZE=5

# ── Enhancement 3: Hierarchical Chunking ──────────────────
USE_HIERARCHICAL_CHUNKING=false
PARENT_CHUNK_SIZE=1000
CHILD_CHUNK_SIZE=300
RETURN_PARENT_CONTEXT=true

# ── Enhancement 4: Query Routing ─────────────────────────
QUERY_ROUTING_ENABLED=false

# ── Enhancement 7: Caching ───────────────────────────────
CACHE_ENABLED=false
CACHE_RETRIEVAL_CAPACITY=200
CACHE_RETRIEVAL_TTL=1800
CACHE_EMBEDDING_CAPACITY=500
CACHE_EMBEDDING_TTL=7200

# ── Enhancement 8: Fallback Handling ─────────────────────
FALLBACK_ENABLED=false
FALLBACK_MIN_SCORE=0.3
FALLBACK_MIN_RESULTS=2

# ── Enhancement 9: Monitoring ────────────────────────────
MONITORING_ENABLED=false
METRICS_MAX_HISTORY=1000
